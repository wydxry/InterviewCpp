## 操作系统中的内存管理
操作系统内存管理：物理内存管理和虚拟内存管理。

物理内存管理：程序装入等概念、交换技术、连续分配管理方式和非连续分配管理方式（分页、分段、段页式）。

虚拟内存管理：虚拟内存管理包括虚虚拟内存概念、请求分页管理方式、页面置换算法、页面分配策略、工作集和抖动。

## Linux中fork函数的作用
fork函数用来创建一个子进程。
fork()函数，其原型如下：
```C++
#include <unistd.h>  
pid_t fork(void);  
```
fork()函数不需要参数，返回值是一个进程标识符PID。返回值有以下三种情况：
（1） 对于父进程，fork()函数返回新创建的子进程的PID。
（2） 对于子进程，fork()函数调用成功会返回0。
（3） 如果创建出错，fork()函数返回-1。

fork()函数创建一个新进程后，会为这个新进程分配进程空间，将父进程的进程空间中的内容复制到子进程的进程空间中，包括父进程的数据段和堆栈段，并且和父进程共享代码段。这时候，子进程和父进程一模一样，都接受系统的调度。因为两个进程都停留在fork()函数中，最后fork()函数会返回两次，一次在父进程中返回，一次在子进程中返回，两次返回的值不一样，如上面的三种情况。

## 伙伴系统


## 进程和线程相比，为什么慢？
1. 进程系统开销显著大于线程开销；线程需要的系统资源更少。
2. 进程切换开销比线程大。多进程切换时需要刷新TLB并获取新的地址空间，然后切换硬件上下文和内核栈；多线程切换时只需要切换硬件上下文和内核栈。
3. 进程通信比线程通信开销大。进程通信需要借助管道、队列、共享内存，需要额外申请空间，通信繁琐；而线程共享进程的内存，如代码段、数据段、扩展段，通信快捷简单，同步开销更小。

## 简述Linux零拷贝的原理？
所谓「零拷贝」描述的是计算机操作系统当中，CPU不执行将数据从一个内存区域，拷贝到另外一个内存区域的任务。通过网络传输文件时，这样通常可以节省 CPU 周期和内存带宽。
### 零拷贝的好处
1. 节省了 CPU 周期，空出的 CPU 可以完成更多其他的任务
2. 减少了内存区域之间数据拷贝，节省内存带宽
3. 减少用户态和内核态之间数据拷贝，提升数据传输效率
4. 应用零拷贝技术，减少用户态和内核态之间的上下文切换
### 零拷贝原理

## 简述epoll和select的区别，epoll为什么高效？
### 区别
1. 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大；而epoll保证了每个fd在整个过程中只会拷贝一次。
2. 每次调用select都需要在内核遍历传递进来的所有fd；而epoll只需要轮询一次fd集合，同时查看就绪链表中有没有就绪的fd就可以了。
3. select支持的文件描述符数量太小了，默认是1024；而epoll没有这个限制，它所支持的fd上限是最大可以打开文件的数目，这个数字一般远大于2048。
### epoll为什么高效
1. select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。
2. select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把当前进程往设备等待队列中挂一次，而epoll只要一次拷贝，而且把当前进程往等待队列上挂也只挂一次，这也能节省不少的开销。

## 说说多路IO复用技术有哪些，区别是什么？
select，poll，epoll都是IO多路复用的机制，I/O多路复用就是通过一种机制，可以**监视多个文件描述符**，一旦某个文件描述符就绪（一般是读就绪或者写就绪），能够通知应用程序进行相应的读写操作。
### 区别
1. poll与select不同，通过一个pollfd数组向内核传递需要关注的事件，故没有描述符个数的限制，pollfd中的events字段和revents分别用于标示关注的事件和发生的事件，故pollfd数组只需要被初始化一次。
2. select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。
3. select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把当前进程往设备等待队列中挂一次，而epoll只要一次拷贝，而且把当前进程往等待队列上挂也只挂一次，这也能节省不少的开销。

## 死锁定义及发生的条件
### 死锁的定义:
两个或两个以上的进程在执行过程中,因争夺共享资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁。这些永远在互相等待的进程称为死锁进程。 
### 产生死锁的必要条件:
1. 互斥条件：指进程对所分配到的资源进行排它性使用,即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源,则请求者只能等待,直至占有资源的进程用毕释放； 
2. 请求和保持条件：指进程已经保持至少一个资源,但又提出了新的资源请求,而该资源已被其它进程占有,此时请求进程阻塞,但又对自己已获得的其它资源保持不放； 
3. 不剥夺条件：指进程已获得的资源,在未使用完之前,不能被剥夺,只能在使用完时由自己释放；
4. 环路等待条件：指在发生死锁时,必然存在一个进程——资源的环形链,即进程集合 {P0,P1,P2,···,Pn} 中的 P0 正在等待一个 P1 占用的资源；P1 正在等待 P2 占用的资源,……,Pn 正在等待已被 P0 占用的资源。

## 内存管理
内存管理主要包括内存的**分配（malloc）**和**释放（free）**，内存的分配可以分为**连续内存分配**和**非连续内存分配**。

**连续分配**：为用户分配一个连续的内存空间，常见的连续分配如块式管理。

**非连续分配**又分为页式存储管理，段式存储管理和段页数存储管理。

* 页式存储管理：页是数据分配的物理单位，页分配是为了实现数据的离散分布，提高内存利用率。它的分区大小是固定的，页分配相较于块有着更小的分配粒度，可能会导致内部内存碎片，不会导致外部内存碎片。通过页表实现物理地址于逻辑地址的对应。
* 段式存储管理：段是数据分配的逻辑单位，段式分配目的是为了更好的反映程序的逻辑结构以更好满足用户需求。它的分区大小是不固定的，会导致外部内存碎片，段相比页拥有实际意义，可以将其分为主程序段，子程序段，数据段和栈段。段是一个二维结构，定位段需要知道它的段名和段内具体物理地址。使用段表来对应物理地址和逻辑地址。
* 段页式存储分配：结合段式分配和页式分配，将主内存区域先分为多个段，在将每个页划分多若干页。结合多段式管理和页式管理的各种优点。

Linux 操作系统是采用**段页式**内存管理方式：页式存储管理能有效地提高内存利用率（解决内存碎片）,而分段存储管理能反映程序的逻辑结构并有利于段的共享。将这两种存储管理方法结合起来,就形成了段页式存储管理方式。 

段页式存储管理方式即先将用户程序分成若干个段,再把每个段分成若干个页,并为每一个段赋予一个段名。

在段页式系统中,为了实现从逻辑地址到物理地址的转换,系统中需要同时配置段表和页表,利用段表和页表进行从用户地址空间到物理内存空间的映射。 

系统为每一个进程建立一张段表,每个分段有一张页表。段表表项中至少包括段号、页表长度和页表始址,页表表项中至少包括页号和块号。在进行地址转换时,首先通过段表查到页表始址,然后通过页表找到页帧号,最终形成物理地址。

## 互斥锁和自旋锁
### 互斥锁 
互斥锁也称为互斥量（Mutex），是一种用来保护临界区的特殊变量， 它可以处于锁定（locked） 状态， 也可以处于解锁（unlocked） 状态： 
- 如果互斥锁是锁定的， 就是某个特定的线程正持有这个互斥锁 
- 如果没有线程持有这个互斥锁，那么这个互斥锁就处于解锁状态 
每个互斥锁内部有一个线程等待队列，用来保存等待该互斥锁的线程。当互斥锁处于解锁状态时， 如果某个线程试图获取这个互斥锁，那么这个线程就可以得到这个互斥锁而不会阻塞；当互斥锁处于锁定状态时， 如果某个线程试图获取这个互斥锁，那么这个线程将阻塞在互斥锁的等待队列内。 
### 自旋锁 
自旋锁与互斥锁类似，但它**不是通过休眠使进程阻塞**，而是在获取锁之前一直**处于忙等（自旋）阻塞状态**。自旋锁可以用于以下情况：**锁被持有的时间短**，而且线程并不希望在重新调度上花费太多的成本。 自旋锁**最多只能被一个可执行线程持有**，如果一个执行线程试图获得一个已经被持有的自旋锁，那么该线程就会一直进行忙循环 - 旋转 - 等待锁重新可用。

## 共享内存
1. 共享内存是**进程间通信**的一种方式。不同进程之间共享的内存通常为**同一段物理内存**，进程可以将同一段物理内存连接到他们自己的地址空间中，**所有的进程都可以访问共享内存中的地址**。如果某个进程向共享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程。
 2. 共享内存的**优点**：因为所有进程共享同一块内存，共享内存在各种进程间通信方式中具有最高的效率。访问共享内存区域和访问进程独有的内存区域一样快，并**不需要通过系统调用或者其它需要切入内核的过程**来完成。同时它也避免了对数据的各种不必要的复制。
 3. 共享内存的**缺点**:共享内存**没有提供同步机制**，这使得我们在使用共享内存进行进程之间的通信时，往往需要借助其他手段来保证进程之间的同步工作。

## 进程调度算法有哪些
调度算法是指根据系统的资源分配策略所规定的资源分配算法。常见的进程调度算法有：
1. **先来先服务（FCFS）调度算法** 
先来先去服务调度算法是一种最简单的调度算法，也称为先进先出或严格排队方案。每次调度都是从后备作业（进程）队列中选择一个或多个最先进入该队列的作业（进程），将它们调入内存，为它们分配资源、创建进程，当每个进程就绪后，它加入就绪队列。当前正运行的进程停止执行，选择在就绪队列中存在时间最长的进程运行。
2. **短作业优先（SJF）调度算法** 短作业优先（SJF）的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业（进程），将它们调入内存运行，短进程优先（SPF）调度算法从就绪队列中选择一个估计运行时间最短的进程，将处理机分配给它，使之立即执行，直到完成或者发生某件事而阻塞时，才释放处理机。
3. **优先级调度算法** 优先级调度算法又称优先权调度算法，该算法既可以用于作业调度，也可以用于进程调度，该算法中的优先级用于描述作业运行的紧迫程度。在作业调度中，优先级调度算法每次从后备作业队列中选择优先级最髙的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列；在进程调度中，优先级调度算法每次从就绪队列中选择优先级最高的进程，将处理机分配给它，使之投入运行。 
4. **高响应比优先调度算法** 高响应比优先调度算法主要用于作业调度，该算法是对 FCFS 调度算法和 SJF 调度算法的一种综合平衡，同时考虑每个作业的等待时间和估计的运行时间。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。 
5. **时间片轮转调度算法** 时间片轮转调度算法主要适用于分时系统。每次调度时，把 CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几 ms 到几百 ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。
6. **多级反馈队列调度算法** 多级反馈队列调度算法是时间片轮转调度算法和优先级调度算法的综合和发展，通过动态调整进程优先级和时间片大小，多级反馈队列调度算法可以兼顾多方面的系统目标。

## 孤儿进程，僵尸进程，如何解决僵尸进程
1. **孤儿进程** 孤儿进程是指一个父进程退出后，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程将被 init 进程（进程号为1）所收养，并且由 init 进程对它们完整状态收集工作，孤儿进程一般不会产生任何危害。 
2. **僵尸进程** 僵尸进程是指一个进程使用 fork() 函数创建子进程，如果子进程退出，而父进程并没有调用 wait() 或者waitpid() 系统调用取得子进程的终止状态，那么子进程的进程描述符仍然保存在系统中，**占用系统资源**，这种进程称为僵尸进程。 
3. **解决僵尸进程** 一般，为了防止产生僵尸进程，在 fork() 子进程之后我们都要及时在父进程中使用 wait() 或者 waitpid() 系统调用，等子进程结束后，父进程回收子进程 PCB 的资源。 同时，当子进程退出的时候，内核都会给父进程一个 SIGCHLD 信号，所以可以**建立一个捕获 SIGCHLD 信号的信号处理函数，在函数体中调用 wait() 或 waitpid()**，就可以清理退出的子进程以达到防止僵尸进程的目的。

## 写时拷贝
写时拷贝顾名思义就是“写的时候才分配内存空间”，这实际上是一种拖延战术。传统的 fork() 系统调用直接把所有的资源复制给新创建的进程，这种实现过于简单并且效率低下，因为它拷贝的数据或许可以共享，或者有时候 fork() 创建新的子进程后，子进程往往要调用一种 exec 函数以执行另一个程序。而 exec 函数会用磁盘上的一个新程序替换当前子进程的正文段、数据段、堆段和栈段，如果之前 fork() 时拷贝了内存，则这时被替换了，这是没有意义的。 Linux 的 fork() 使用写时拷贝（Copy-on-write）页实现。写时拷贝是一种可以推迟甚至避免拷贝数据的技术。内核此时并不复制整个进程的地址空间，而是让父子进程共享同一个地址空间。只用在需要写入的时候才会复制地址空间，从而使各个进行拥有各自的地址空间。也就是说，资源的复制是在需要写入的时候才会进行，在此之前，只有以只读方式共享。这种技术使地址空间上的页的拷贝被推迟到实际发生写入的时候，大大提高了效率。

## 动态库静态库的区别和优缺点
### 静态库和动态库的区别： 
1. 命令方式不同 
- 静态库命名 Linux : libxxx.a lib : 前缀（固定） xxx : 库的名字，自己起 .a : 后缀（固定） Windows : libxxx.lib 
- 动态库命名 Linux : libxxx.so lib : 前缀（固定） xxx : 库的名字，自己起 .so : 后缀（固定） Windows : libxxx.dll 
2. 链接时间和方式不同 
- 静态库的链接是将整个函数库的所有数据在**编译**时都整合进了目标代码 
- 动态库的链接是程序**执行**到哪个函数链接哪个函数的库 
### 静态库和动态库的优缺点： 
1. 静态库优缺点 
- 优点：发布程序时无需提供静态库，移植方便，**运行速度相对快**些 
- 缺点：静态链接生成的可执行文件体积较大，**消耗内存**，如果所使用的静态库发生更新改变，程序必须重新编译，更新麻烦。 
2. 动态库优缺点 
- 优点：更加**节省内存并减少页面交换**，动态库改变并不影响使用的程序，动态函数库升级比较方便 
- 缺点：**发布程序时需要提供动态库**

## 条件变量？？
条件变量是利用线程间共享的全局变量进行同步的一种机制，主要包括两个动作：一个线程等待"条件变量的条件成立"而挂起；另一个线程使"条件成立"（给出条件成立信号）。为了防止竞争，条件变量的使用总是和一个互斥锁结合在一起。 使用条件变量可以以原子方式阻塞线程，直到某个特定条件为真为止。条件变量始终与互斥锁一起使用，对条件的测试是在互斥锁（互斥）的保护下进行的。如果条件为假，线程通常会基于条件变量阻塞，并以原子方式释放等待条件变化的互斥锁。如果另一个线程更改了条件，该线程可能会向相关的条件变量发出信号，从而使一个或多个等待的线程执行以下操作： 唤醒 再次获取互斥锁 重新评估条件。

## 进程通信中的管道实现原理是什么？
操作系统在内核中开辟一块缓冲区（称为管道）用于通信。管道是一种两个进程间进行单向通信的机制。因为这种单向性，管道又称为半双工管道，所以其使用是有一定的局限性的。半双工是指数据只能由一个进程流向另一个进程（一个管道负责读，一个管道负责写）；如果是全双工通信，需要建立两个管道。管道分为无名管道和命名管道，无名管道只能用于具有亲缘关系的进程直接的通信（父子进程或者兄弟进程），可以看作一种特殊的文件，管道本质是一种文件；命名管道可以允许无亲缘关系进程间的通信。

管道原型如下：
```C++
＃include <unistd.h>  
int pipe(int fd[2]); 
```
pipe()函数创建的管道处于一个进程中间，因此一个进程在由 pipe()创建管道后，一般再使用fork() 建立一个子进程，然后通过管道实现父子进程间的通信。管道两端可分别用描述字fd[0]以及fd[1]来描述。注意管道的两端的任务是固定的，即一端只能用于读，由描述字fd[0]表示，称其为管道读端；另 一端则只能用于写，由描述字fd[1]来表示，称其为管道写端。如果试图从管道写端读取数据，或者向管道读端写入数据都将发生错误。一般文件的 I/O 函数都可以用于管道，如close()、read()、write()等。

具体步骤如下：
1. 父进程调用pipe开辟管道,得到两个文件描述符指向管道的两端。
2. 父进程调用fork创建子进程,那么子进程也有两个文件描述符指向同一管道。
3. 父进程关闭管道读端,子进程关闭管道写端。父进程可以往管道里写,子进程可以从管道里读,管道是用环形队列实现的,数据从写端流入从读端流出,这样就实现了进程间通信。

实现父子进程间的管道通信：
```C++
#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#define INPUT 0
#define OUTPUT 1
int main()
{
    //创建管道
    int fd[2];
    pipe(fd);

    //创建子进程
    pid_t pid = fork();
    if (pid < 0)
    {
        printf("fork error!\n");
        exit(-1);
    }
    else if (pid == 0)
    {   //执行子进程
        printf("Child process is starting...\n");
        
        //子进程向父进程写数据，关闭管道的读端
        close(fd[INPUT]);
        write(fd[OUTPUT], "hello parent!", strlen("hello parent!"));
        exit(0);
    }
    else
    {  //执行父进程
        printf("Parent process is starting......\n");
        
        //父进程从管道读取子进程写的数据 ，关闭管道的写端
        close(fd[OUTPUT]);
        char buf[255];
        int output = read(fd[INPUT], buf, sizeof(buf));
        printf("%d bytes of data from child process: %s\n", output, buf);
    }
    return 0;
}  
```

## 简述mmap的原理和使用场景
原理：mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写脏页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read, write等系统调用函数。相反，内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。

使用场景：
1. 对同一块区域频繁读写操作；
2. 可用于实现用户空间和内核空间的高效交互
3. 可提供进程间共享内存及相互通信
4. 可实现高效的大规模数据传输。

## 协程是轻量级线程，轻量级表现在哪里？
1. 协程调用跟切换比线程效率高：协程执行效率极高。协程不需要多线程的锁机制，可以不加锁的访问全局变量，所以上下文的切换非常快。
2. 协程占用内存少：执行协程只需要极少的栈内存（大概是4～5KB），而默认情况下，线程栈的大小为1MB。
3. 切换开销更少：协程直接操作栈基本没有内核切换的开销，所以切换开销比线程少。

## 说说常见信号有哪些，表示什么含义？
![常见信号](/img/signal.png)

## 说说线程间通信的方式有哪些？
线程间的通信方式包括**临界区**、**互斥量**、**信号量**、**条件变量**、**读写锁**：

1. 临界区：每个线程中访问临界资源的那段代码称为临界区（Critical Section）（临界资源是一次仅允许一个线程使用的共享资源）。每次只准许一个线程进入临界区，进入后不允许其他线程进入。不论是硬件临界资源，还是软件临界资源，多个线程必须互斥地对它进行访问。
2. 互斥量：采用互斥对象机制，只有拥有互斥对象的线程才可以访问。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。
3. 信号量：计数器，允许多个线程同时访问同一个资源。
4. 条件变量：通过条件变量通知操作的方式来保持多线程同步。
5. 读写锁：读写锁与互斥量类似。但互斥量要么是锁住状态，要么就是不加锁状态。读写锁一次只允许一个线程写，但允许一次多个线程读，这样效率就比互斥锁要高。

## 说说什么是死锁，产生的条件，如何解决？
1. 死锁: 是指多个进程在执行过程中，因争夺资源而造成了互相等待。此时系统产生了死锁。比如两只羊过独木桥，若两只羊互不相让，争着过桥，就产生死锁。

2. 产生的条件：死锁发生有四个必要条件：

（1）互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问，只能等待，直到进程使用完成后释放该资源；

（2）请求保持条件：进程获得一定资源后，又对其他资源发出请求，但该资源被其他进程占有，此时请求阻塞，而且该进程不会释放自己已经占有的资源；

（3）不可剥夺条件：进程已获得的资源，只能自己释放，不可剥夺；

（4）环路等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。

3. 如何解决：

（1）资源一次性分配，从而解决请求保持的问题

（2）可剥夺资源：当进程新的资源未得到满足时，释放已有的资源；

（3）资源有序分配：资源按序号递增，进程请求按递增请求，释放则相反。

##  有了进程，为什么还要有线程？
1. 原因

进程在早期的多任务操作系统中是基本的执行单元。每次进程切换，都要先保存进程资源然后再恢复，这称为上下文切换。但是进程频繁切换将引起额外开销，从而严重影响系统的性能。为了减少进程切换的开销，人们把两个任务放到一个进程中，每个任务用一个更小粒度的执行单元来实现并发执行，这就是线程。

2. 线程与进程对比

（1）进程间的信息难以共享。由于除去只读代码段外，父子进程并未共享内存，因此必须采用一些进程间通信方式，在进程间进行信息交换。多个线程共享进程的内存，如代码段、数据段、扩展段，线程间进行信息交换十分方便。

（2）调用 fork() 来创建进程的代价相对较高，即便利用写时复制技术，仍然需要复制诸如内存页表和文件描述符表之类的多种进程属性，这意味着 fork() 调用在时间上的开销依然不菲。创建线程比创建进程通常要快 10 倍甚至更多。线程间是共享虚拟地址空间的，无需采用写时复制来复制内存，也无需复制页表。

## 说说什么是信号量，有什么作用？
1. 概念：信号量本质上是一个计数器，用于多进程对共享数据对象的读取，它主要是用来保护共享资源（信号量也属于临界资源），使得资源在一个时刻只有一个进程独享。

2. 原理：由于信号量只能进行两种操作等待和发送信号，即P(sv)和V(sv)，具体的行为如下：

（1）P(sv)操作：如果sv的值大于零，就给它减1；如果它的值为零，就挂起该进程的执行（信号量的值为正，进程获得该资源的使用权，进程将信号量减1，表示它使用了一个资源单位）。

（2）V(sv)操作：如果有其他进程因等待sv而被挂起，就让它恢复运行，如果没有进程因等待sv而挂起，就给它加1（若此时信号量的值为0，则进程进入挂起状态，直到信号量的值大于0，若进程被唤醒则返回至第一步）。

3. 作用：用于多进程对共享数据对象的读取，它主要是用来保护共享资源（信号量也属于临界资源），使得资源在一个时刻只有一个进程独享。

## 进程、线程的中断切换的过程是怎样的？
上下文切换指的是内核（操作系统的核心）在CPU上对进程或者线程进行切换。

1. 进程上下文切换

（1）保护被中断进程的处理器现场信息

（2）修改被中断进程的进程控制块有关信息，如进程状态等

（3）把被中断进程的进程控制块加入有关队列

（4）选择下一个占有处理器运行的进程

（5）根据被选中进程设置操作系统用到的地址转换和存储保护信息

​ 切换页目录以使用新的地址空间

​ 切换内核栈和硬件上下文（包括分配的内存，数据段，堆栈段等）

（6）根据被选中进程恢复处理器现场

2. 线程上下文切换

（1）保护被中断线程的处理器现场信息

（2）修改被中断线程的线程控制块有关信息，如线程状态等

（3）把被中断线程的线程控制块加入有关队列

（4）选择下一个占有处理器运行的线程

（5）根据被选中线程设置操作系统用到的存储保护信息

​ 切换内核栈和硬件上下文（切换堆栈，以及各寄存器）

（6）根据被选中线程恢复处理器现场

## 说说线程池的设计思路，线程池中线程的数量由什么确定？
### 为什么要创建线程池
创建线程和销毁线程的花销是比较大的，这些时间有可能比处理业务的时间还要长。这样频繁的创建线程和销毁线程，再加上业务工作线程，消耗系统资源的时间，可能导致系统资源不足。同时线程池也是为了提升系统效率。

### 设计思路
实现线程池有以下几个步骤：

（1）设置一个生产者消费者队列，作为临界资源。

（2）初始化n个线程，并让其运行起来，加锁去队列里取任务运行

（3）当任务队列为空时，所有线程阻塞。

（4）当生产者队列来了一个任务后，先对队列加锁，把任务挂到队列上，然后使用条件变量去通知阻塞中的一个线程来处理。

### 线程池中线程数量
线程数量和哪些因素有关：CPU，IO、并行、并发
1. 如果是CPU密集型应用，则线程池大小设置为：CPU数目+1
2. 如果是IO密集型应用，则线程池大小设置为：2 * CPU数目+1
3. 最佳线程数目 = （线程等待时间与线程CPU时间之比 + 1）* CPU数目
4. 线程等待时间所占比例越高，需要越多线程。线程CPU时间所占比例越高，需要越少线程。

### 线程池的核心线程与普通线程
任务队列可以存放100个任务，此时为空，线程池里有10个核心线程，若突然来了10个任务，那么刚好10个核心线程直接处理；若又来了90个任务，此时核心线程来不及处理，那么有80个任务先入队列，再创建核心线程处理任务；若又来了120个任务，此时任务队列已满，不得已，就得创建20个普通线程来处理多余的任务。

## 进程和线程相比，为什么慢？
1. 进程系统开销显著大于线程开销；线程需要的系统资源更少。
2. 进程切换开销比线程大。多进程切换时需要刷新TLB并获取新的地址空间，然后切换硬件上下文和内核栈；多线程切换时只需要切换硬件上下文和内核栈。
3. 进程通信比线程通信开销大。进程通信需要借助管道、队列、共享内存，需要额外申请空间，通信繁琐；而线程共享进程的内存，如代码段、数据段、扩展段，通信快捷简单，同步开销更小。

## 简述epoll和select的区别，epoll为什么高效？
1. 区别：

（1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大；而epoll保证了每个fd在整个过程中只会拷贝一次。

（2）每次调用select都需要在内核遍历传递进来的所有fd；而epoll只需要轮询一次fd集合，同时查看就绪链表中有没有就绪的fd就可以了。

（3）select支持的文件描述符数量太小了，默认是1024；而epoll没有这个限制，它所支持的fd上限是最大可以打开文件的数目，这个数字一般远大于2048。

2. epoll为什么高效：

（1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。

（2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把当前进程往设备等待队列中挂一次，而epoll只要一次拷贝，而且把当前进程往等待队列上挂也只挂一次，这也能节省不少的开销。

## 说说多路IO复用技术有哪些，区别是什么？
1. select，poll，epoll都是IO多路复用的机制，I/O多路复用就是通过一种机制，可以监视多个文件描述符，一旦某个文件描述符就绪（一般是读就绪或者写就绪），能够通知应用程序进行相应的读写操作。

2. 区别：

（1）poll与select不同，通过一个pollfd数组向内核传递需要关注的事件，故没有描述符个数的限制，pollfd中的events字段和revents分别用于标示关注的事件和发生的事件，故pollfd数组只需要被初始化一次。

（2）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。

（3）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把当前进程往设备等待队列中挂一次，而epoll只要一次拷贝，而且把当前进程往等待队列上挂也只挂一次，这也能节省不少的开销。

## 简述socket中select，epoll的使用场景和区别，epoll水平触发与边缘触发的区别？
1. select，epoll的使用场景：都是IO多路复用的机制，应用于高并发的网络编程的场景。I/O多路复用就是通过一种机制，可以监视多个文件描述符，一旦某个文件描述符就绪（一般是读就绪或者写就绪），能够通知应用程序进行相应的读写操作。

2. select，epoll的区别：

（1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大；而epoll保证了每个fd在整个过程中只会拷贝一次。

（2）每次调用select都需要在内核遍历传递进来的所有fd；而epoll只需要轮询一次fd集合，同时查看就绪链表中有没有就绪的fd就可以了。

（3）select支持的文件描述符数量太小了，默认是1024；而epoll没有这个限制，它所支持的fd上限是最大可以打开文件的数目，这个数字一般远大于2048。

3. epoll水平触发与边缘触发的区别

(1) LT模式（水平触发）下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作；

(2) 在ET（边缘触发）模式中，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。

## 说说Reactor、Proactor模式。
在高性能的I/O设计中，有两个比较著名的模式Reactor和Proactor模式，其中Reactor模式用于同步I/O，而Proactor运用于异步I/O操作。

1. Reactor模式：Reactor模式应用于同步I/O的场景。

Reactor中读操作的具体步骤如下：

（1）应用程序注册读就需事件和相关联的事件处理器

（2）事件分离器等待事件的发生

（3）当发生读就需事件的时候，事件分离器调用第一步注册的事件处理器

（4）事件处理器首先执行实际的读取操作，然后根据读取到的内容进行进一步的处理

2. Proactor模式：Proactor模式应用于异步I/O的场景。

Proactor中读操作的具体步骤如下：

（1）应用程序初始化一个异步读取操作，然后注册相应的事件处理器，此时事件处理器不关注读取就绪事件，而是关注读取完成事件，这是区别于Reactor的关键。

（2）事件分离器等待读取操作完成事件

（3）在事件分离器等待读取操作完成的时候，操作系统调用内核线程完成读取操作，并将读取的内容放入用户传递过来的缓存区中。这也是区别于Reactor的一点，Proactor中，应用程序需要传递缓存区。

（4）事件分离器捕获到读取完成事件后，激活应用程序注册的事件处理器，事件处理器直接从缓存区读取数据，而不需要进行实际的读取操作。

3. 区别：从上面可以看出，Reactor中需要应用程序自己读取或者写入数据，而Proactor模式中，应用程序不需要用户再自己接收数据，直接使用就可以了，操作系统会将数据从内核拷贝到用户区。

## IO模型的类型
（1）阻塞IO：调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的检查这个函数有没有返回，必须等这个函数返回后才能进行下一步动作。

（2）非阻塞IO：非阻塞等待，每隔一段时间就去检查IO事件是否就绪。没有就绪就可以做其他事情。

（3）信号驱动IO：Linux用套接口进行信号驱动IO，安装一个信号处理函数，进程继续运行并不阻塞，当IO事件就绪，进程收到SIGIO信号，然后处理IO事件。

（4）IO多路复用：Linux用select/poll函数实现IO复用模型，这两个函数也会使进程阻塞，但是和阻塞IO所不同的是这两个函数可以同时阻塞多个IO操作。而且可以同时对多个读操作、写操作的IO函数进行检查。知道有数据可读或可写时，才真正调用IO操作函数。

（5）异步IO：Linux中，可以调用aio_read函数告诉内核描述字缓冲区指针和缓冲区的大小、文件偏移及通知的方式，然后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。用户可以直接去使用数据。

前四种模型--阻塞IO、非阻塞IO、多路复用IO和信号驱动IO都属于同步模式，因为其中真正的IO操作(函数)都将会阻塞进程，只有异步IO模型真正实现了IO操作的异步性。

## 简述同步与异步的区别，阻塞与非阻塞的区别？
1. 同步与异步的区别：

同步：是所有的操作都做完，才返回给用户结果。即写完数据库之后，再响应用户，用户体验不好。

异步：不用等所有操作都做完，就响应用户请求。即先响应用户请求，然后慢慢去写数据库，用户体验较好。

2. 阻塞与非阻塞的区别：

阻塞：调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的检查这个函数有没有返回，必须等这个函数返回后才能进行下一步动作。

非阻塞：非阻塞等待，每隔一段时间就去检查IO事件是否就绪。没有就绪就可以做其他事情。

## BIO、NIO有什么区别？
BIO（Blocking I/O）：阻塞IO。调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的检查这个函数有没有返回，必须等这个函数返回后才能进行下一步动作。

NIO（New I/O）：同时支持阻塞与非阻塞模式，NIO的做法是叫一个线程不断的轮询每个IO的状态，看看是否有IO的状态发生了改变，从而进行下一步的操作。

## 请说一下socket网络编程中客户端和服务端用到哪些函数？
1. 服务器端函数：

（1）socket创建一个套接字

（2）bind绑定ip和port

（3）listen使套接字变为可以被动链接

（4）accept等待客户端的链接

（5）write/read接收发送数据

（6）close关闭连接

2. 客户端函数：

（1）创建一个socket，用函数socket()

（2）bind绑定ip和port

（3）连接服务器，用函数connect()

（4）收发数据，用函数send()和recv()，或read()和write()

（5）close关闭连接

![socket网络编程](/img/socket.png)

## 说说软链接和硬链接的区别
1. 定义不同

软链接又叫符号链接，这个文件包含了另一个文件的路径名。可以是任意文件或目录，可以链接不同文件系统的文件。

硬链接就是一个文件的一个或多个文件名。把文件名和计算机文件系统使用的节点号链接起来。因此我们可以用多个文件名与同一个文件进行链接，这些文件名可以在同一目录或不同目录。

2. 限制不同

硬链接只能对已存在的文件进行创建，不能交叉文件系统进行硬链接的创建；

软链接可对不存在的文件或目录创建软链接；可交叉文件系统；

3. 创建方式不同

硬链接不能对目录进行创建，只可对文件创建；

软链接可对文件或目录创建；

4. 影响不同

删除一个硬链接文件并不影响其他有相同 inode 号的文件。

删除软链接并不影响被指向的文件，但若被指向的原文件被删除，则相关软连接被称为死链接（即 dangling link，若被指向路径文件被重新创建，死链接可恢复为正常的软链接）。


## 简述操作系统如何申请以及管理内存的？
1. 操作系统如何管理内存：

物理内存：物理内存有四个层次，分别是寄存器、高速缓存、主存、磁盘。

寄存器：速度最快、量少、价格贵。

高速缓存：次之。

主存：再次之。

磁盘：速度最慢、量多、价格便宜。

操作系统会对物理内存进行管理，有一个部分称为内存管理器(memory manager)，它的主要工作是有效的管理内存，记录哪些内存是正在使用的，在进程需要时分配内存以及在进程完成时回收内存。

2. 虚拟内存：操作系统为每一个进程分配一个独立的地址空间，但是虚拟内存。虚拟内存与物理内存存在映射关系，通过页表寻址完成虚拟地址和物理地址的转换。

3. 操作系统如何申请内存：从操作系统角度来看，进程分配内存有两种方式，分别由两个系统调用完成：*brk和mmap

## 操作系统的内存管理
操作系统内存管理：总的来说，操作系统内存管理包括物理内存管理和虚拟内存管理

物理内存管理：
包括程序装入等概念、交换技术、连续分配管理方式和非连续分配管理方式（分页、分段、段页式）

虚拟内存管理：
虚拟内存管理包括虚拟内存概念、请求分页管理方式、页面置换算法、页面分配策略、工作集和抖动。

## 说说进程有多少种状态？
进程有五种状态：创建、就绪、执行、阻塞、终止。一个进程创建后，被放入队列处于就绪状态，等待操作系统调度执行，执行过程中可能切换到阻塞状态（并发），任务完成后，进程销毁终止。

1. 创建状态
    
    一个应用程序从系统上启动，首先就是进入创建状态，需要获取系统资源创建进程管理块（PCB：Process Control Block）完成资源分配。

2. 就绪状态
    
    在创建状态完成之后，进程已经准备好，处于就绪状态，但是还未获得处理器资源，无法运行。

3. 运行状态
    
    获取处理器资源，被系统调度，当具有时间片开始进入运行状态。如果进程的时间片用完了就进入就绪状态。

4. 阻塞状态
    
    在运行状态期间，如果进行了阻塞的操作，如耗时的I/O操作，此时进程暂时无法操作就进入到了阻塞状态，在这些操作完成后就进入就绪状态。等待再次获取处理器资源，被系统调度，当具有时间片就进入运行状态。

5. 终止状态
    
    进程结束或者被系统终止，进入终止状态